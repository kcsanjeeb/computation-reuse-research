{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7189d0e3",
   "metadata": {},
   "source": [
    "# End-to-end SVCCA & CKA Report (Single Notebook)\n",
    "\n",
    "This notebook:\n",
    "1. Connects to MinIO (S3-compatible).\n",
    "2. Discovers trials under a prefix (e.g., `exp1/`).\n",
    "3. Loads per-trial activation snapshots (`.npz`) for selected epochs and layers.\n",
    "4. Computes **Linear CKA** and **SVCCA** pairwise across trials.\n",
    "5. Produces heatmaps and summary tables using **matplotlib** (no seaborn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f4c545",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T10:58:14.862201Z",
     "start_time": "2025-11-01T10:58:14.851333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: 10.249.190.44:9000\n",
      "Bucket  : katib-artifacts\n",
      "Prefix  : exp1\n",
      "Epochs  : [1, 2, 4, 8, 16, 20]\n",
      "Layers  : ['conv1', 'layer1.1.relu', 'layer2.1.relu', 'layer3.1.relu', 'layer4.1.relu', 'fc']\n",
      "SVCCA_VAR_KEEP: 0.99  | Upload: True\n",
      "Outdir  : /home/san/mac-linux/study/NCA-GENL/kubeflow-experiments/SVCCA/output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "MINIO_ENDPOINT = os.getenv(\"MINIO_ENDPOINT\", \"10.249.190.44:9000\")\n",
    "MINIO_BUCKET   = os.getenv(\"MINIO_BUCKET\",   \"katib-artifacts\")\n",
    "MINIO_ACCESS   = os.getenv(\"MINIO_ACCESS_KEY\", \"minioadmin\")\n",
    "MINIO_SECRET   = os.getenv(\"MINIO_SECRET_KEY\", \"minioadmin\")\n",
    "MINIO_PREFIX   = os.getenv(\"MINIO_PREFIX\",   \"exp1\")\n",
    "\n",
    "ANALYSIS_EPOCHS = [int(x) for x in os.getenv(\"ANALYSIS_EPOCHS\", \"1,2,4,8,16,20\").split(\",\")]\n",
    "ANALYSIS_LAYERS = os.getenv(\n",
    "    \"ANALYSIS_LAYERS\",\n",
    "    \"conv1,layer1.1.relu,layer2.1.relu,layer3.1.relu,layer4.1.relu,fc\"\n",
    ").split(\",\")\n",
    "\n",
    "SVCCA_VAR_KEEP = float(os.getenv(\"SVCCA_VAR_KEEP\", \"0.99\"))\n",
    "UPLOAD_RESULTS = os.getenv(\"UPLOAD_RESULTS\", \"1\") == \"1\"\n",
    "OUTDIR_LOCAL   = os.getenv(\"OUTDIR_LOCAL\", \"/home/san/mac-linux/study/NCA-GENL/kubeflow-experiments/SVCCA/output\")\n",
    "\n",
    "\n",
    "print(\"Endpoint:\", MINIO_ENDPOINT)\n",
    "print(\"Bucket  :\", MINIO_BUCKET)\n",
    "print(\"Prefix  :\", MINIO_PREFIX)\n",
    "print(\"Epochs  :\", ANALYSIS_EPOCHS)\n",
    "print(\"Layers  :\", ANALYSIS_LAYERS)\n",
    "print(\"SVCCA_VAR_KEEP:\", SVCCA_VAR_KEEP, \" | Upload:\", UPLOAD_RESULTS)\n",
    "print(\"Outdir  :\", OUTDIR_LOCAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2347fdd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T10:58:16.472965Z",
     "start_time": "2025-11-01T10:58:16.455648Z"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import boto3\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"boto3 is required to access MinIO\") from e\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    TORCH_OK = True\n",
    "except Exception:\n",
    "    TORCH_OK = False\n",
    "\n",
    "def s3_client():\n",
    "    ep = MINIO_ENDPOINT if MINIO_ENDPOINT.startswith(\"http\") else \"http://\" + MINIO_ENDPOINT\n",
    "    return boto3.client(\n",
    "        \"s3\",\n",
    "        endpoint_url=ep,\n",
    "        aws_access_key_id=MINIO_ACCESS,\n",
    "        aws_secret_access_key=MINIO_SECRET,\n",
    "    )\n",
    "\n",
    "s3 = s3_client()\n",
    "Path(OUTDIR_LOCAL).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1f480cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T10:58:21.081844Z",
     "start_time": "2025-11-01T10:58:20.809636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found trials: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cifar10-reuse-discovery-2dzlbqn4',\n",
       " 'cifar10-reuse-discovery-7dhrcnrv',\n",
       " 'cifar10-reuse-discovery-88fkk4m2',\n",
       " 'cifar10-reuse-discovery-9gwg6rqx',\n",
       " 'cifar10-reuse-discovery-9lc75hwb']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_trials():\n",
    "    trials = set()\n",
    "    base = f\"{MINIO_PREFIX}/\"\n",
    "    resp = s3.list_objects_v2(Bucket=MINIO_BUCKET, Prefix=base)\n",
    "    while True:\n",
    "        for obj in resp.get(\"Contents\", []):\n",
    "            parts = obj[\"Key\"].split(\"/\")\n",
    "            if len(parts) >= 4 and parts[2] == \"activations\":\n",
    "                trials.add(parts[1])\n",
    "        if resp.get(\"IsTruncated\"):\n",
    "            resp = s3.list_objects_v2(Bucket=MINIO_BUCKET, Prefix=base,\n",
    "                                      ContinuationToken=resp[\"NextContinuationToken\"])\n",
    "        else:\n",
    "            break\n",
    "    return sorted(trials)\n",
    "\n",
    "def fetch_npz_array(key: str, arr_key: str = \"activations\"):\n",
    "    obj = s3.get_object(Bucket=MINIO_BUCKET, Key=key)\n",
    "    data = obj[\"Body\"].read()\n",
    "    with np.load(io.BytesIO(data)) as npz:\n",
    "        return npz[arr_key]\n",
    "\n",
    "def fetch_acts(trial: str, epoch: int, layer: str):\n",
    "    key = f\"{MINIO_PREFIX}/{trial}/activations/epoch_{epoch}/{layer}.npz\"\n",
    "    try:\n",
    "        A = fetch_npz_array(key, \"activations\")\n",
    "        A = A - A.mean(axis=0, keepdims=True)\n",
    "        return A\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def fetch_best(trial: str):\n",
    "    if not TORCH_OK:\n",
    "        return None, None\n",
    "    key = f\"{MINIO_PREFIX}/{trial}/checkpoints/best.pt\"\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=MINIO_BUCKET, Key=key)\n",
    "        buf = obj[\"Body\"].read()\n",
    "        state = torch.load(io.BytesIO(buf), map_location=\"cpu\")\n",
    "        acc = float(state.get(\"val_acc\")) if isinstance(state, dict) and \"val_acc\" in state else None\n",
    "        ep  = int(state.get(\"epoch\")) if isinstance(state, dict) and \"epoch\" in state else None\n",
    "        return acc, ep\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "trials = list_trials()\n",
    "print(\"Found trials:\", len(trials))\n",
    "trials[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f66324ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T10:58:25.195253Z",
     "start_time": "2025-11-01T10:58:25.184812Z"
    }
   },
   "outputs": [],
   "source": [
    "def center_gram(X):\n",
    "    G = X @ X.T\n",
    "    n = G.shape[0]\n",
    "    H = np.eye(n) - np.ones((n, n))/n\n",
    "    return H @ G @ H\n",
    "\n",
    "def cka_linear(X, Y):\n",
    "    n = min(len(X), len(Y))\n",
    "    if len(X) != len(Y):\n",
    "        X = X[:n]; Y = Y[:n]\n",
    "    Kx = center_gram(X)\n",
    "    Ky = center_gram(Y)\n",
    "    hsic = np.sum(Kx * Ky)\n",
    "    denom = np.sqrt(np.sum(Kx*Kx) * np.sum(Ky*Ky)) + 1e-12\n",
    "    return float(hsic / denom)\n",
    "\n",
    "def svd_keep(X, var_keep=0.99):\n",
    "    U, S, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    var = S**2\n",
    "    cum = np.cumsum(var) / (var.sum() + 1e-12)\n",
    "    k = int(np.searchsorted(cum, var_keep) + 1)\n",
    "    Xr = U[:, :k] * S[:k]\n",
    "    return Xr\n",
    "\n",
    "def invsqrt(mat):\n",
    "    eigvals, eigvecs = np.linalg.eigh(mat)\n",
    "    eigvals = np.clip(eigvals, 1e-12, None)\n",
    "    Dm12 = np.diag(1.0/np.sqrt(eigvals))\n",
    "    return eigvecs @ Dm12 @ eigvecs.T\n",
    "\n",
    "def svcca_score(X, Y, var_keep=0.99):\n",
    "    n = min(len(X), len(Y))\n",
    "    if len(X) != len(Y):\n",
    "        X = X[:n]; Y = Y[:n]\n",
    "    Xr = svd_keep(X, var_keep)\n",
    "    Yr = svd_keep(Y, var_keep)\n",
    "    Cxx = Xr.T @ Xr\n",
    "    Cyy = Yr.T @ Yr\n",
    "    Cxy = Xr.T @ Yr\n",
    "    Cxx_invh = invsqrt(Cxx)\n",
    "    Cyy_invh = invsqrt(Cyy)\n",
    "    T = Cxx_invh @ Cxy @ Cyy_invh\n",
    "    s = np.linalg.svd(T, compute_uv=False)\n",
    "    return float(np.mean(s)), s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746b82c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:00:20.323308Z",
     "start_time": "2025-11-01T10:58:29.040611Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "summary_rows = []\n",
    "\n",
    "for t in trials:\n",
    "    acc, ep = fetch_best(t)\n",
    "    summary_rows.append({\"trial\": t, \"best_val_accuracy\": acc, \"best_epoch\": ep})\n",
    "\n",
    "for epoch in ANALYSIS_EPOCHS:\n",
    "    for layer in ANALYSIS_LAYERS:\n",
    "        acts = {}\n",
    "        for t in trials:\n",
    "            A = fetch_acts(t, epoch, layer)\n",
    "            if A is not None and A.ndim == 2 and A.shape[0] >= 2:\n",
    "                acts[t] = A\n",
    "        kept = sorted(acts.keys())\n",
    "        n = len(kept)\n",
    "        if n < 2:\n",
    "            print(f\"[skip] epoch={epoch} layer={layer}: not enough trials with data\")\n",
    "            continue\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                ti, tj = kept[i], kept[j]\n",
    "                c = cka_linear(acts[ti], acts[tj])\n",
    "                s_mean, _ = svcca_score(acts[ti], acts[tj], var_keep=SVCCA_VAR_KEEP)\n",
    "                rows.append([epoch, layer, \"CKA\", ti, tj, c])\n",
    "                rows.append([epoch, layer, \"SVCCA\", ti, tj, s_mean])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"epoch\",\"layer\",\"metric\",\"trial_i\",\"trial_j\",\"score\"])\n",
    "df_summary = pd.DataFrame(summary_rows)\n",
    "\n",
    "print(\"Pairwise rows:\", len(df))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1380ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "pairwise_csv = str(Path(OUTDIR_LOCAL) / \"pairwise_scores.csv\")\n",
    "summary_csv  = str(Path(OUTDIR_LOCAL) / \"trial_summary.csv\")\n",
    "\n",
    "Path(OUTDIR_LOCAL).mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(pairwise_csv, index=False)\n",
    "df_summary.to_csv(summary_csv, index=False)\n",
    "print(\"Wrote:\", pairwise_csv)\n",
    "print(\"Wrote:\", summary_csv)\n",
    "\n",
    "def upload_csv(local_path, s3_key):\n",
    "    with open(local_path, \"rb\") as fh:\n",
    "        s3.put_object(Bucket=MINIO_BUCKET, Key=s3_key, Body=fh, ContentType=\"text/csv\")\n",
    "\n",
    "if UPLOAD_RESULTS:\n",
    "    upload_csv(pairwise_csv, f\"{MINIO_PREFIX}/analysis/pairwise_scores.csv\")\n",
    "    upload_csv(summary_csv,  f\"{MINIO_PREFIX}/analysis/trial_summary.csv\")\n",
    "    print(\"Uploaded to s3://%s/%s/analysis/\" % (MINIO_BUCKET, MINIO_PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d386fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_for(dframe, epoch, layer, metric):\n",
    "    d = dframe[(dframe['epoch']==epoch) & (dframe['layer']==layer) & (dframe['metric']==metric)]\n",
    "    trials = sorted(set(d['trial_i']).union(set(d['trial_j'])))\n",
    "    idx = {t:i for i,t in enumerate(trials)}\n",
    "    M = np.eye(len(trials))\n",
    "    for _, row in d.iterrows():\n",
    "        i, j = idx[row['trial_i']], idx[row['trial_j']]\n",
    "        M[i,j] = M[j,i] = float(row['score'])\n",
    "    return trials, M\n",
    "\n",
    "epochs = sorted(df['epoch'].unique().tolist())\n",
    "layers = sorted(df['layer'].unique().tolist())\n",
    "metrics = sorted(df['metric'].unique().tolist())\n",
    "\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Layers:\", layers)\n",
    "print(\"Metrics:\", metrics)\n",
    "\n",
    "E = epochs[-1] if epochs else None\n",
    "L = layers[min(2, len(layers)-1)] if layers else None\n",
    "E, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe7880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_heatmap(M, labels, title):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(M, aspect='auto')\n",
    "    plt.xticks(range(len(labels)), labels, rotation=90)\n",
    "    plt.yticks(range(len(labels)), labels)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if E is not None and L is not None:\n",
    "    trials_, M_cka = matrix_for(df, E, L, 'CKA')\n",
    "    _,       M_sv  = matrix_for(df, E, L, 'SVCCA')\n",
    "    show_heatmap(M_cka, trials_, f\"CKA heatmap (epoch={E}, layer={L})\")\n",
    "    show_heatmap(M_sv,  trials_, f\"SVCCA heatmap (epoch={E}, layer={L})\")\n",
    "else:\n",
    "    print(\"No data yet to plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d677d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if E is not None and L is not None:\n",
    "    d = df[(df['epoch']==E) & (df['layer']==L)]\n",
    "    dd = d.pivot_table(index=['trial_i','trial_j'], columns='metric', values='score').reset_index()\n",
    "    dd = dd.dropna()\n",
    "\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.scatter(dd['CKA'], dd['SVCCA'])\n",
    "    plt.xlabel(\"CKA\")\n",
    "    plt.ylabel(\"SVCCA\")\n",
    "    plt.title(f\"CKA vs SVCCA (epoch={E}, layer={L})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    display(dd.head())\n",
    "else:\n",
    "    print(\"No data for scatter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cce98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_by_layer = df.groupby(['layer','metric'])['score'].agg(['mean','median','std','count']).reset_index()\n",
    "summary_by_epoch = df.groupby(['epoch','metric'])['score'].agg(['mean','median','std','count']).reset_index()\n",
    "\n",
    "summary_by_layer.sort_values(['metric','mean'], ascending=[True, False], inplace=True)\n",
    "summary_by_epoch.sort_values(['metric','epoch'], ascending=[True, True], inplace=True)\n",
    "\n",
    "print(\"Summary by layer (top 10):\")\n",
    "display(summary_by_layer.head(10))\n",
    "\n",
    "print(\"Summary by epoch:\")\n",
    "display(summary_by_epoch)\n",
    "\n",
    "if not df_summary.empty:\n",
    "    print(\"Best validation accuracy (if available):\")\n",
    "    display(df_summary.sort_values('best_val_accuracy', ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
